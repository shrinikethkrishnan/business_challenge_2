{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we are going to import the libraries and modules we will be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId     False\n",
       "HomePlanet       True\n",
       "CryoSleep        True\n",
       "Cabin            True\n",
       "Destination      True\n",
       "Age              True\n",
       "VIP              True\n",
       "RoomService      True\n",
       "FoodCourt        True\n",
       "ShoppingMall     True\n",
       "Spa              True\n",
       "VRDeck           True\n",
       "Name             True\n",
       "Transported     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** All the columns have null values, except for ```PassengerId``` and ```Transported```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of null:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "HomePlanet      201\n",
       "CryoSleep       217\n",
       "Cabin           199\n",
       "Destination     182\n",
       "Age             179\n",
       "VIP             203\n",
       "RoomService     181\n",
       "FoodCourt       183\n",
       "ShoppingMall    208\n",
       "Spa             183\n",
       "VRDeck          188\n",
       "Name            200\n",
       "Transported       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Sum of null:')\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am much more comfortable with doing all this on a new copy, just in case I mess up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy = train_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make an ```Expenses``` column. \n",
    "**if someone is in cryosleep, they are not spending any money**. So, knowing someone's expenses can help us impute values for ```CryoSleep```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy['Expenses'] = train_df_copy[['RoomService', 'FoodCourt',\n",
    "                                           'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we can't really guess anyone's age, I'll just impute these null values with the median.  **only people who are 13+ have expenses**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy.Age = train_df_copy.Age.fillna(train_df_copy.Age.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our dataset now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Expenses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "      <td>736.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "      <td>10383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "      <td>5176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "      <td>1091.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  Expenses  \n",
       "0        False       0.0  \n",
       "1         True     736.0  \n",
       "2        False   10383.0  \n",
       "3        False    5176.0  \n",
       "4         True    1091.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " make a new column for cryosleep, with **all** values equal to **False** (or 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy['Cryosleep'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for every row where ```Expenses``` is ```0```, we're going to put ``1`` as the value. Because **if someone has not spent any money, they are proably in cryosleep**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy.loc[train_df_copy['Expenses'] == 0, 'Cryosleep'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to set this column's value to ``1`` wherever the original ```CryoSleep``` is equal to **True**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy.loc[train_df_copy.CryoSleep.astype('str') == 'True', 'Cryosleep'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversely, we will put it to ``0`` wherever ``CryoSleep`` is **False**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy.loc[train_df_copy.CryoSleep.astype('str') == 'False', 'Cryosleep'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at this new column now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Expenses</th>\n",
       "      <th>Cryosleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  Expenses  Cryosleep  \n",
       "0        False       0.0          0  \n",
       "1         True     736.0          0  \n",
       "2        False   10383.0          0  \n",
       "3        False    5176.0          0  \n",
       "4         True    1091.0          0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have done here is:\n",
    "\n",
    "* First, we set **all** values for cryosleep as false.\n",
    "* Next, we set cryosleep as true for **everyone who hasn't spent any money**.\n",
    "* Finally, we used the original `Cryosleep colum`, to correct cryosleep status for the people who **haven't spent any money, but aren't in cryosleep**. Just in case our last step **incorrectly** classified them as **being in cryosleep**.\n",
    "\n",
    "\n",
    "\n",
    "Now, let's just replace the original column with this one. There's probably a better way of doing this than how I did it here here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy['Cryosleep'] = train_df_copy['Cryosleep'].astype('bool')\n",
    "train_df_copy['CryoSleep'] = train_df_copy['Cryosleep']\n",
    "train_df_copy.drop('Cryosleep',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take another look at our dataset now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Expenses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "      <td>736.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "      <td>10383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "      <td>5176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "      <td>1091.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet  CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa      False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth      False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa      False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa      False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth      False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  Expenses  \n",
       "0        False       0.0  \n",
       "1         True     736.0  \n",
       "2        False   10383.0  \n",
       "3        False    5176.0  \n",
       "4         True    1091.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have now replaced the values of our original `CryoSleep` column, that had missing values, with the values of our newly created `Cryosleep` column which doesn't have any null values. Then we dropped our new column.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_copy.CryoSleep.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy.drop('Name',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the amenities, we can easily impute null values for ```Cryosleep``` == True, since **we know they are going to be zero as the person is in cryosleep**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoomService     0\n",
       "FoodCourt       0\n",
       "ShoppingMall    0\n",
       "Spa             0\n",
       "VRDeck          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_copy.loc[train_df_copy.CryoSleep == True,['RoomService', 'FoodCourt','ShoppingMall', 'Spa', 'VRDeck']] = 0\n",
    "train_df_copy.loc[train_df_copy.CryoSleep == True,['RoomService', 'FoodCourt','ShoppingMall', 'Spa', 'VRDeck']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before dealing with the rest of the amenities' values, let's make some more new columns to aid us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy['Adults'] = train_df_copy['Age'] >= 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a column now that tells us if **someone is 13+** and **is spending money**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy['Adult_and_spending'] = (train_df_copy['Expenses'] > 0) & (train_df_copy['Age'] >=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the rows that are **True** for our new `Adult_and_spending` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Expenses</th>\n",
       "      <th>Adults</th>\n",
       "      <th>Adult_and_spending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>True</td>\n",
       "      <td>736.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0005_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/P</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>774.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8687</th>\n",
       "      <td>9275_03</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/97/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3208.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3540.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/98/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>False</td>\n",
       "      <td>8536.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1500/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4637.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4826.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5040 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet  CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "1        0002_01      Earth      False     F/0/S    TRAPPIST-1e  24.0  False   \n",
       "2        0003_01     Europa      False     A/0/S    TRAPPIST-1e  58.0   True   \n",
       "3        0003_02     Europa      False     A/0/S    TRAPPIST-1e  33.0  False   \n",
       "4        0004_01      Earth      False     F/1/S    TRAPPIST-1e  16.0  False   \n",
       "5        0005_01      Earth      False     F/0/P  PSO J318.5-22  44.0  False   \n",
       "...          ...        ...        ...       ...            ...   ...    ...   \n",
       "8687     9275_03     Europa      False    A/97/P    TRAPPIST-1e  30.0  False   \n",
       "8688     9276_01     Europa      False    A/98/P    55 Cancri e  41.0   True   \n",
       "8690     9279_01      Earth      False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
       "8691     9280_01     Europa      False   E/608/S    55 Cancri e  32.0  False   \n",
       "8692     9280_02     Europa      False   E/608/S    TRAPPIST-1e  44.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck  Transported  \\\n",
       "1           109.0        9.0          25.0   549.0    44.0         True   \n",
       "2            43.0     3576.0           0.0  6715.0    49.0        False   \n",
       "3             0.0     1283.0         371.0  3329.0   193.0        False   \n",
       "4           303.0       70.0         151.0   565.0     2.0         True   \n",
       "5             0.0      483.0           0.0   291.0     0.0         True   \n",
       "...           ...        ...           ...     ...     ...          ...   \n",
       "8687          0.0     3208.0           0.0     2.0   330.0         True   \n",
       "8688          0.0     6819.0           0.0  1643.0    74.0        False   \n",
       "8690          0.0        0.0        1872.0     1.0     0.0         True   \n",
       "8691          0.0     1049.0           0.0   353.0  3235.0        False   \n",
       "8692        126.0     4688.0           0.0     0.0    12.0         True   \n",
       "\n",
       "      Expenses  Adults  Adult_and_spending  \n",
       "1        736.0    True                True  \n",
       "2      10383.0    True                True  \n",
       "3       5176.0    True                True  \n",
       "4       1091.0    True                True  \n",
       "5        774.0    True                True  \n",
       "...        ...     ...                 ...  \n",
       "8687    3540.0    True                True  \n",
       "8688    8536.0    True                True  \n",
       "8690    1873.0    True                True  \n",
       "8691    4637.0    True                True  \n",
       "8692    4826.0    True                True  \n",
       "\n",
       "[5040 rows x 16 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_copy.loc[train_df_copy.Adult_and_spending == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are **5040** people who **are 13+** and **are spending money**.\n",
    "\n",
    "Now we are going to impute the values for our amenities.\n",
    "\n",
    "We know if someone is **not an adult** and has **zero expenses**, they are either below 13, which means they **definitely** haven't spent on **any** amenities, or they are **in cryosleep**, which again means they **definitely** haven't spent on amenities.\n",
    "\n",
    "So, wherever we have `Adult_and_spending` == False, we'll impute them with `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy.RoomService = train_df_copy.RoomService.fillna(train_df_copy.RoomService.mean())\n",
    "train_df_copy.loc[train_df_copy.Adult_and_spending ==False, 'RoomService'] = 0\n",
    "\n",
    "train_df_copy.FoodCourt = train_df_copy.FoodCourt.fillna(train_df_copy.FoodCourt.mean())\n",
    "train_df_copy.loc[train_df_copy.Adult_and_spending ==False, 'FoodCourt'] = 0\n",
    "\n",
    "train_df_copy.ShoppingMall = train_df_copy.ShoppingMall.fillna(train_df_copy.ShoppingMall.mean())\n",
    "train_df_copy.loc[train_df_copy.Adult_and_spending ==False, 'ShoppingMall'] = 0\n",
    "\n",
    "train_df_copy.Spa = train_df_copy.Spa.fillna(train_df_copy.Spa.mean())\n",
    "train_df_copy.loc[train_df_copy.Adult_and_spending ==False, 'Spa'] = 0\n",
    "\n",
    "train_df_copy.VRDeck = train_df_copy.VRDeck.fillna(train_df_copy.VRDeck.mean())\n",
    "train_df_copy.loc[train_df_copy.Adult_and_spending ==False, 'VRDeck'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoomService     0\n",
       "FoodCourt       0\n",
       "ShoppingMall    0\n",
       "Spa             0\n",
       "VRDeck          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_copy[['RoomService', 'FoodCourt','ShoppingMall', 'Spa', 'VRDeck']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect.\n",
    "\n",
    "For the remaining columns, we can't figure out what values to fill in this manner. So we are just going to fill them with the values that the majority of people have in the dataset, i.e., the **mode**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Earth\n",
       "Name: HomePlanet, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_copy.HomePlanet.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    TRAPPIST-1e\n",
       "Name: Destination, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_copy.Destination.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "Name: VIP, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_copy.VIP.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, these are the values we will be imputing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy.HomePlanet = train_df_copy.HomePlanet.fillna('Earth')\n",
    "train_df_copy.Destination = train_df_copy.Destination.fillna('TRAPPIST-1e')\n",
    "train_df_copy.VIP = train_df_copy.VIP.fillna('False')\n",
    "train_df_copy.VIP = train_df_copy.VIP.astype('bool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aaand done!\n",
    "\n",
    "Let's see how much we are done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId             0\n",
       "HomePlanet              0\n",
       "CryoSleep               0\n",
       "Cabin                 199\n",
       "Destination             0\n",
       "Age                     0\n",
       "VIP                     0\n",
       "RoomService             0\n",
       "FoodCourt               0\n",
       "ShoppingMall            0\n",
       "Spa                     0\n",
       "VRDeck                  0\n",
       "Transported             0\n",
       "Expenses                0\n",
       "Adults                  0\n",
       "Adult_and_spending      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cabin is the only column that remains with null values! \n",
    "\n",
    "Filling this is not easy due to my limited skill. I am just going to use **ffill** to fill these null values. What that does is basically use the **previous** value to impute the **missing** one. \n",
    "\n",
    "So, for example, if we have a dataset like:\n",
    "\n",
    "[1, 2, 3, **null**, 4]\n",
    "\n",
    "If we use **ffill** on this, it'll become:\n",
    "\n",
    "[1, 2, 3, **3**, 4]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy['Cabin'] = train_df_copy.Cabin.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId           0\n",
       "HomePlanet            0\n",
       "CryoSleep             0\n",
       "Cabin                 0\n",
       "Destination           0\n",
       "Age                   0\n",
       "VIP                   0\n",
       "RoomService           0\n",
       "FoodCourt             0\n",
       "ShoppingMall          0\n",
       "Spa                   0\n",
       "VRDeck                0\n",
       "Transported           0\n",
       "Expenses              0\n",
       "Adults                0\n",
       "Adult_and_spending    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so, we are done with imputing. Time to move on to feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the features that I am going to add to this dataset (again, I got the idea for them [here](https://www.kaggle.com/code/mateuszk013/spaceship-titanic-81-eda-ml/notebook))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy['Group_nums'] = train_df_copy.PassengerId.apply(lambda x: x.split('_')).apply(lambda x: x[0])\n",
    "train_df_copy['Grouped'] = ((train_df_copy['Group_nums'].value_counts() > 1).reindex(train_df_copy['Group_nums'])).tolist()\n",
    "train_df_copy['Deck'] = train_df_copy.Cabin.apply(lambda x: str(x).split('/')).apply(lambda x: x[0])\n",
    "train_df_copy['Side'] = train_df_copy.Cabin.apply(lambda x: str(x).split('/')).apply(lambda x: x[2])\n",
    "train_df_copy['Has_expenses'] = train_df_copy['Expenses'] > 0\n",
    "train_df_copy['Is_Embryo'] = train_df_copy['Age'] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These specifiy:\n",
    "\n",
    "* If someone was **alone** or **in a group**.\n",
    "* Which **deck** someone was in.\n",
    "* Which side (**Starboard** or **Port**).\n",
    "* If the passenger was **0 years old** (i.e, an **embryo**).\n",
    "\n",
    "Let's get rid of our temporary columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy.drop(['Adult_and_spending','Group_nums','Expenses'],axis=1,\\\n",
    "                   inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our final dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Adults</th>\n",
       "      <th>Grouped</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Side</th>\n",
       "      <th>Has_expenses</th>\n",
       "      <th>Is_Embryo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>P</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet  CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa      False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth      False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa      False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa      False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth      False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck  Transported  Adults  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0        False    True   \n",
       "1        109.0        9.0          25.0   549.0    44.0         True    True   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0        False    True   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0        False    True   \n",
       "4        303.0       70.0         151.0   565.0     2.0         True    True   \n",
       "\n",
       "   Grouped Deck Side  Has_expenses  Is_Embryo  \n",
       "0    False    B    P         False      False  \n",
       "1    False    F    S          True      False  \n",
       "2     True    A    S          True      False  \n",
       "3     True    A    S          True      False  \n",
       "4    False    F    S          True      False  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy.to_csv('Cleaned imputed data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Since even our test data has missing values, we have to do **all** that to our test data as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_copy = test_df.copy()\n",
    "\n",
    "test_df_copy['Expenses'] = test_df_copy[['RoomService', 'FoodCourt',\n",
    "                                           'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
    "\n",
    "test_df_copy.Age = test_df_copy.Age.fillna(test_df_copy.Age.median())\n",
    "\n",
    "test_df_copy['Adult_spending_awake'] = (test_df_copy['Expenses'] > 0)\\\n",
    "                                     & (test_df_copy['Age'] >= 13)\\\n",
    "                                     & (test_df_copy['CryoSleep'] == False)\n",
    "\n",
    "test_df_copy['Cryosleep'] = 0\n",
    "test_df_copy.loc[test_df_copy['Expenses'] == 0, 'Cryosleep'] = 1\n",
    "test_df_copy.loc[test_df_copy.CryoSleep.astype('str') == 'True', 'Cryosleep'] = 1\n",
    "test_df_copy.loc[test_df_copy.CryoSleep.astype('str') == 'False', 'Cryosleep'] = 0\n",
    "test_df_copy['Cryosleep'] = test_df_copy['Cryosleep'].astype('bool')\n",
    "test_df_copy['CryoSleep'] = test_df_copy['Cryosleep']\n",
    "test_df_copy.drop('Cryosleep',axis=1,inplace=True)\n",
    "test_df_copy.drop('Name',axis=1,inplace=True)\n",
    "\n",
    "test_df_copy.loc[test_df_copy.CryoSleep == True,['RoomService', 'FoodCourt','ShoppingMall', 'Spa', 'VRDeck']] = 0\n",
    "\n",
    "test_df_copy['Adults'] = test_df_copy['Age'] >= 13\n",
    "\n",
    "test_df_copy['Adult_and_spending'] = (test_df_copy['Expenses'] > 0) & (test_df_copy['Age'] >=13)\n",
    "test_df_copy.loc[test_df_copy.Adult_and_spending == True]\n",
    "\n",
    "test_df_copy.RoomService = test_df_copy.RoomService.fillna(test_df_copy.RoomService.mean())\n",
    "test_df_copy.loc[test_df_copy.Adult_and_spending ==False, 'RoomService'] = 0\n",
    "\n",
    "test_df_copy.FoodCourt = test_df_copy.FoodCourt.fillna(test_df_copy.FoodCourt.mean())\n",
    "test_df_copy.loc[test_df_copy.Adult_and_spending ==False, 'FoodCourt'] = 0\n",
    "\n",
    "test_df_copy.ShoppingMall = test_df_copy.ShoppingMall.fillna(test_df_copy.ShoppingMall.mean())\n",
    "test_df_copy.loc[test_df_copy.Adult_and_spending ==False, 'ShoppingMall'] = 0\n",
    "\n",
    "test_df_copy.Spa = test_df_copy.Spa.fillna(test_df_copy.Spa.mean())\n",
    "test_df_copy.loc[test_df_copy.Adult_and_spending ==False, 'Spa'] = 0\n",
    "\n",
    "test_df_copy.VRDeck = test_df_copy.VRDeck.fillna(test_df_copy.VRDeck.mean())\n",
    "test_df_copy.loc[test_df_copy.Adult_and_spending ==False, 'VRDeck'] = 0\n",
    "\n",
    "test_df_copy.HomePlanet = test_df_copy.HomePlanet.fillna('Earth')\n",
    "test_df_copy.Destination = test_df_copy.Destination.fillna('TRAPPIST-1e')\n",
    "test_df_copy.VIP = test_df_copy.VIP.fillna('False')\n",
    "test_df_copy.VIP = test_df_copy.VIP.astype('bool')\n",
    "\n",
    "test_df_copy['Cabin'] = test_df_copy.Cabin.fillna(method='ffill')\n",
    "\n",
    "test_df_copy['Group_nums'] = test_df_copy.PassengerId.apply(lambda x: x.split('_')).apply(lambda x: x[0])\n",
    "test_df_copy['Grouped'] = ((test_df_copy['Group_nums'].value_counts() > 1).reindex(test_df_copy['Group_nums'])).tolist()\n",
    "test_df_copy['Deck'] = test_df_copy.Cabin.apply(lambda x: str(x).split('/')).apply(lambda x: x[0])\n",
    "test_df_copy['Side'] = test_df_copy.Cabin.apply(lambda x: str(x).split('/')).apply(lambda x: x[2])\n",
    "test_df_copy['Has_expenses'] = test_df_copy['Expenses'] > 0\n",
    "test_df_copy['Is_Embryo'] = test_df_copy['Age'] == 0\n",
    "\n",
    "test_df_copy.columns\n",
    "test_df_copy.drop(['Expenses', 'Adult_spending_awake', 'Adult_and_spending','Adults'],axis=1, inplace=True)\n",
    "\n",
    "test_df_copy.to_csv('Cleaned test data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import **Logistic Regression**. I'm also going to import **train-test split**, just for some light evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we import the csv's that we saved earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Cleaned and imputed data.csv')\n",
    "df_test = pd.read_csv('Cleaned and imputed test data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Adults</th>\n",
       "      <th>Grouped</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Side</th>\n",
       "      <th>Has_expenses</th>\n",
       "      <th>Is_Embryo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>P</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet  CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa      False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth      False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa      False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa      False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth      False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck  Transported  Adults  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0        False    True   \n",
       "1        109.0        9.0          25.0   549.0    44.0         True    True   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0        False    True   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0        False    True   \n",
       "4        303.0       70.0         151.0   565.0     2.0         True    True   \n",
       "\n",
       "   Grouped Deck Side  Has_expenses  Is_Embryo  \n",
       "0    False    B    P         False      False  \n",
       "1    False    F    S          True      False  \n",
       "2     True    A    S          True      False  \n",
       "3     True    A    S          True      False  \n",
       "4    False    F    S          True      False  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Group_nums</th>\n",
       "      <th>Grouped</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Side</th>\n",
       "      <th>Has_expenses</th>\n",
       "      <th>Is_Embryo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/4/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>C/0/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>C/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/5/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet  CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0013_01      Earth       True  G/3/S  TRAPPIST-1e  27.0  False   \n",
       "1     0018_01      Earth      False  F/4/S  TRAPPIST-1e  19.0  False   \n",
       "2     0019_01     Europa       True  C/0/S  55 Cancri e  31.0  False   \n",
       "3     0021_01     Europa      False  C/1/S  TRAPPIST-1e  38.0  False   \n",
       "4     0023_01      Earth      False  F/5/S  TRAPPIST-1e  20.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck  Group_nums  Grouped  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0          13    False   \n",
       "1          0.0        9.0           0.0  2823.0     0.0          18    False   \n",
       "2          0.0        0.0           0.0     0.0     0.0          19    False   \n",
       "3          0.0     6652.0           0.0   181.0   585.0          21    False   \n",
       "4         10.0        0.0         635.0     0.0     0.0          23    False   \n",
       "\n",
       "  Deck Side  Has_expenses  Is_Embryo  \n",
       "0    G    S         False      False  \n",
       "1    F    S          True      False  \n",
       "2    C    S         False      False  \n",
       "3    C    S          True      False  \n",
       "4    F    S          True      False  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      object\n",
       "HomePlanet       object\n",
       "CryoSleep          bool\n",
       "Cabin            object\n",
       "Destination      object\n",
       "Age             float64\n",
       "VIP                bool\n",
       "RoomService     float64\n",
       "FoodCourt       float64\n",
       "ShoppingMall    float64\n",
       "Spa             float64\n",
       "VRDeck          float64\n",
       "Transported        bool\n",
       "Adults             bool\n",
       "Grouped            bool\n",
       "Deck             object\n",
       "Side             object\n",
       "Has_expenses       bool\n",
       "Is_Embryo          bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['HomePlanet', 'CryoSleep', 'Destination', 'Age', 'VIP',\n",
    "            'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', \n",
    "            'Grouped', 'Deck', 'Has_expenses', 'Side', 'Is_Embryo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df_train[features])\n",
    "y = df_train['Transported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit and score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8003679852805887"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad.\n",
    "\n",
    "Since we actually have to predict the **test** set that Kaggle has provided, we want to use all of the **train** data to train the model. The more data the model gets to learn from, the better the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.792016565052341"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LogisticRegression(max_iter=10000)\n",
    "model2.fit(X,y)\n",
    "model2.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict our test set now and save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log2 = model2.predict(pd.get_dummies(df_test[features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using **K-Neighbors Classifier**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And use **GridSearchCV** to get the optimal K value (code commented out as it takes time to run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn = KNeighborsClassifier()\n",
    "# param_grid = {'n_neighbors':np.arange(2,15)}\n",
    "# knn_gscv = GridSearchCV(knn, param_grid, cv=5)\n",
    "# knn_gscv.fit(X,y)\n",
    "# knn_gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8149085471068676"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn2 = KNeighborsClassifier(n_neighbors=14)\n",
    "knn2.fit(X,y)\n",
    "knn2.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = knn2.predict(pd.get_dummies(df_test[features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8130679857356494"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbr = GradientBoostingClassifier(random_state = 1)\n",
    "  \n",
    "# Fit to training set\n",
    "gbr.fit(X, y)\n",
    "gbr.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems slightly worse than our K-Neighbors Classifier. But still, we'll keep its predictions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y_gbr = gbr.predict(pd.get_dummies((df_test[features])))\n",
    "pred_y_gbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    \"n_estimators\":[5,50,100],\n",
    "    \"max_depth\":[1,3,5],\n",
    "   \"learning_rate\":[0.01,0.1,1]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "cv = RandomizedSearchCV(gbc, parameters, n_iter=27, scoring='accuracy', n_jobs=-1, cv=5, random_state=1)\n",
    "cv.fit(X,y)\n",
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.831013459105027"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc1 = GradientBoostingClassifier(n_estimators=50,max_depth=5,learning_rate=0.1) #best params from gscv\n",
    "\n",
    "gbc1.fit(X,y)\n",
    "gbc1.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying the AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Giving a 0 on kaggle so we need to find something else\n",
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "#from sklearn.datasets import make_classification\n",
    "#X, y = make_classification(n_samples=8040, n_features=27,\n",
    "#                           n_informative=2, n_redundant=0,\n",
    "#                           random_state=0, shuffle=False)\n",
    "#clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "#clf.fit(X, y)\n",
    "#AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "#clf.predict(pd.get_dummies((df_test[features])))\n",
    "#array([1])\n",
    "#clf.score(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#pred_y_gbr2 = clf.predict(pd.get_dummies((df_test[features])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9771376939813695"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)\n",
    "regr = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "regr.fit(X, y)\n",
    "AdaBoostRegressor(n_estimators=100, random_state=0)\n",
    "regr.predict([[0, 0, 0, 0]])\n",
    "\n",
    "regr.score(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ExtraTrees Regressor - NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27081747066124695"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, random_state=0)\n",
    "reg = ExtraTreesRegressor(n_estimators=100, random_state=0).fit(\n",
    "    X_train, y_train)\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.913"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "X, y = make_hastie_10_2(random_state=0)\n",
    "X_train, X_test = X[:2000], X[2000:]\n",
    "y_train, y_test = y[:2000], y[2000:]\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "     max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Regressor - NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43848663277068134"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = make_regression(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X, y, random_state=0)\n",
    "reg = GradientBoostingRegressor(random_state=0)\n",
    "reg.fit(X_train, y_train)\n",
    "GradientBoostingRegressor(random_state=0)\n",
    "reg.predict(X_test[1:2])\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining 3 models: GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "550 fits failed out of a total of 1000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "550 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 586, in fit\n",
      "    n_stages = self._fit_stages(\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 663, in _fit_stages\n",
      "    raw_predictions = self._fit_stage(\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 246, in _fit_stage\n",
      "    tree.fit(X, residual, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 308, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [  nan   nan 0.957   nan 0.944   nan 0.943   nan 0.95    nan 0.947 0.945\n",
      " 0.945   nan 0.944   nan   nan 0.952 0.957   nan   nan 0.941   nan 0.944\n",
      " 0.958   nan 0.937 0.955   nan   nan 0.95  0.956 0.96  0.94  0.956   nan\n",
      " 0.957   nan   nan   nan   nan   nan 0.956   nan   nan 0.959   nan 0.957\n",
      " 0.949   nan 0.956 0.942   nan   nan   nan 0.943   nan   nan 0.955 0.948\n",
      "   nan   nan   nan 0.953   nan   nan   nan 0.95    nan   nan   nan   nan\n",
      " 0.953   nan   nan   nan 0.95  0.95    nan   nan   nan 0.951   nan   nan\n",
      "   nan   nan 0.943   nan 0.954 0.955 0.957   nan   nan 0.956 0.951   nan\n",
      " 0.959   nan 0.946 0.955]\n",
      "  warnings.warn(\n",
      "C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "570 fits failed out of a total of 1000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "300 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 308, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "270 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 187, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 308, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [  nan 0.951 0.95  0.952 0.954   nan 0.947   nan 0.95    nan   nan   nan\n",
      "   nan   nan   nan 0.951 0.948   nan   nan 0.952 0.947   nan   nan 0.948\n",
      "   nan 0.954 0.95    nan   nan 0.95    nan   nan   nan 0.947   nan 0.946\n",
      " 0.953 0.953   nan   nan 0.948 0.956 0.953   nan   nan 0.948   nan 0.956\n",
      "   nan 0.95  0.952 0.953 0.947 0.947 0.95    nan 0.952   nan   nan 0.955\n",
      "   nan   nan   nan 0.945   nan   nan   nan   nan   nan 0.953   nan   nan\n",
      "   nan 0.952   nan   nan   nan   nan   nan 0.955   nan   nan   nan   nan\n",
      " 0.951   nan 0.951 0.95    nan   nan   nan 0.955 0.954 0.952   nan 0.954\n",
      "   nan   nan   nan 0.952]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.985"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from scipy.stats import randint, uniform, reciprocal\n",
    "\n",
    "# Define the classifiers\n",
    "gbc_clf = GradientBoostingClassifier(random_state=42)\n",
    "et_clf = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter distributions\n",
    "param_dist_gbc = {\n",
    "    \"n_estimators\": randint(100, 200),\n",
    "    \"learning_rate\": reciprocal(0.001, 1.0),\n",
    "    \"max_depth\": randint(5, 15),\n",
    "    \"max_leaf_nodes\": randint(2, 12),\n",
    "    \"min_samples_split\": randint(2, 12),\n",
    "    \"min_samples_leaf\": randint(1, 8),\n",
    "    \"min_impurity_decrease\": uniform(0.001, 0.1),\n",
    "    \"n_iter_no_change\": randint(5, 15),\n",
    "    \"max_features\": randint(10, 25),\n",
    "}\n",
    "param_dist_et = {\n",
    "    \"n_estimators\": randint(100, 200),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": randint(5, 15),\n",
    "    \"max_features\": randint(10, 25),\n",
    "    \"min_samples_split\": randint(2, 12),\n",
    "    \"min_samples_leaf\": randint(1, 8),\n",
    "    \"bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "# Define the random search objects\n",
    "gbc_rnd_search = RandomizedSearchCV(\n",
    "    gbc_clf,\n",
    "    param_distributions=param_dist_gbc,\n",
    "    cv=10,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    random_state=42,\n",
    ")\n",
    "et_rnd_search = RandomizedSearchCV(\n",
    "    et_clf,\n",
    "    param_distributions=param_dist_et,\n",
    "    cv=10,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Perform the random searches\n",
    "gbc_rnd_search.fit(X, y)\n",
    "et_rnd_search.fit(X, y)\n",
    "\n",
    "# Get the best estimators\n",
    "gbc_best = gbc_rnd_search.best_estimator_\n",
    "et_best = et_rnd_search.best_estimator_\n",
    "\n",
    "# Define the voting classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[(\"gbc\", gbc_best), (\"et\", et_best)],\n",
    "    voting=\"hard\",\n",
    ")\n",
    "\n",
    "# Fit the voting classifier\n",
    "voting_clf.fit(X, y)\n",
    "\n",
    "# Get the accuracy score\n",
    "voting_clf.score(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining: RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "550 fits failed out of a total of 1000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "550 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 586, in fit\n",
      "    n_stages = self._fit_stages(\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 663, in _fit_stages\n",
      "    raw_predictions = self._fit_stage(\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 246, in _fit_stage\n",
      "    tree.fit(X, residual, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 308, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\jkobe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [  nan   nan 0.957   nan 0.944   nan 0.943   nan 0.95    nan 0.947 0.945\n",
      " 0.945   nan 0.944   nan   nan 0.952 0.957   nan   nan 0.941   nan 0.944\n",
      " 0.958   nan 0.937 0.955   nan   nan 0.95  0.956 0.96  0.94  0.956   nan\n",
      " 0.957   nan   nan   nan   nan   nan 0.956   nan   nan 0.959   nan 0.957\n",
      " 0.949   nan 0.956 0.942   nan   nan   nan 0.943   nan   nan 0.955 0.948\n",
      "   nan   nan   nan 0.953   nan   nan   nan 0.95    nan   nan   nan   nan\n",
      " 0.953   nan   nan   nan 0.95  0.95    nan   nan   nan 0.951   nan   nan\n",
      "   nan   nan 0.943   nan 0.954 0.955 0.957   nan   nan 0.956 0.951   nan\n",
      " 0.959   nan 0.946 0.955]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Scores:  0.96\n",
      "Random Forest Classifier Scores:  0.9480000000000001\n",
      "K-Nearest Neighbors Classifier Scores:  0.9240000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from scipy.stats import randint, uniform, reciprocal\n",
    "\n",
    "# Define the classifiers\n",
    "gbc_clf = GradientBoostingClassifier(random_state=42)\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "# Define the parameter distributions\n",
    "param_dist_gbc = {\n",
    "    \"n_estimators\": randint(100, 200),\n",
    "    \"learning_rate\": reciprocal(0.001, 1.0),\n",
    "    \"max_depth\": randint(5, 15),\n",
    "    \"max_leaf_nodes\": randint(2, 12),\n",
    "    \"min_samples_split\": randint(2, 12),\n",
    "    \"min_samples_leaf\": randint(1, 8),\n",
    "    \"min_impurity_decrease\": uniform(0.001, 0.1),\n",
    "    \"n_iter_no_change\": randint(5, 15),\n",
    "    \"max_features\": randint(10, 25),\n",
    "}\n",
    "param_dist_rf = {\n",
    "    \"n_estimators\": randint(100, 200),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": randint(5, 15),\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"min_samples_split\": randint(2, 12),\n",
    "    \"min_samples_leaf\": randint(1, 8),\n",
    "}\n",
    "param_dist_knn = {\n",
    "    \"n_neighbors\": randint(1, 20),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "    \"leaf_size\": randint(10, 50),\n",
    "}\n",
    "\n",
    "# Define the random search objects\n",
    "gbc_rnd_search = RandomizedSearchCV(\n",
    "    gbc_clf,\n",
    "    param_distributions=param_dist_gbc,\n",
    "    cv=10,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    random_state=42,\n",
    ")\n",
    "rf_rnd_search = RandomizedSearchCV(\n",
    "    rf_clf,\n",
    "    param_distributions=param_dist_rf,\n",
    "    cv=10,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    random_state=42,\n",
    ")\n",
    "knn_rnd_search = RandomizedSearchCV(\n",
    "    knn_clf,\n",
    "    param_distributions=param_dist_knn,\n",
    "    cv=10,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Perform the random searches\n",
    "gbc_rnd_search.fit(X, y)\n",
    "rf_rnd_search.fit(X, y)\n",
    "knn_rnd_search.fit(X, y)\n",
    "\n",
    "# Get the best estimators\n",
    "gbc_best = gbc_rnd_search.best_estimator_\n",
    "rf_best = rf_rnd_search.best_estimator_\n",
    "knn_best = knn_rnd_search.best_estimator_\n",
    "\n",
    "# Compute the cross-validation scores\n",
    "gbc_scores = cross_val_score(gbc_best, X, y, cv=10)\n",
    "rf_scores = cross_val_score(rf_best, X, y, cv=10)\n",
    "knn_scores = cross_val_score(knn_best, X, y, cv=10)\n",
    "\n",
    "# Print the scores\n",
    "print(\"Gradient Boosting Classifier Scores: \", gbc_scores.mean())\n",
    "print(\"Random Forest Classifier Scores: \", rf_scores.mean())\n",
    "print(\"K-Nearest Neighbors Classifier Scores: \", knn_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying the Ensemble Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "X, y = load_iris(return_X_y=True)\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "    ('svr', make_pipeline(StandardScaler(),\n",
    "     LinearSVC(random_state=42))) ]\n",
    "clf = StackingClassifier(\n",
    "estimators=estimators, final_estimator=LogisticRegression())\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, stratify=y, random_state=42 )\n",
    "clf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 2 2 2]\n",
      "[1 1 1 2 2 2]\n",
      "Accuracy score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "clf1 = LogisticRegression(multi_class='multinomial', random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "y = np.array([1, 1, 1, 2, 2, 2])\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "         ('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "eclf1 = eclf1.fit(X, y)\n",
    "print(eclf1.predict(X))\n",
    "\n",
    "np.array_equal(eclf1.named_estimators_.lr.predict(X),\n",
    "                eclf1.named_estimators_['lr'].predict(X))\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[\n",
    "         ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
    "         voting='soft')\n",
    "eclf2 = eclf2.fit(X, y)\n",
    "print(eclf2.predict(X))\n",
    "\n",
    "# Define X_test and y_test\n",
    "X_test = np.array([[0, 0], [-1, -2], [4, 2]])\n",
    "y_test = np.array([1, 1, 2])\n",
    "\n",
    "print(\"Accuracy score:\", eclf2.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HistGradientBoostingClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = HistGradientBoostingClassifier().fit(X, y)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinations of Ensemble Methods with KNN as a base "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.pipeline import Pipeline\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#import warnings\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "#param_grid_knn = {'knn__n_neighbors': [3, 5, 7]}\n",
    "#param_grid_adaboost = {'adaboost__n_estimators': [50, 100, 150], 'adaboost__learning_rate': [0.1, 0.5, 1]}\n",
    "\n",
    "#pipe = Pipeline([\n",
    "#    ('scaler', StandardScaler()),\n",
    "#    ('knn', KNeighborsClassifier()),\n",
    "#    ('adaboost', AdaBoostClassifier())\n",
    "#])\n",
    "#param_grid = {**param_grid_knn, **param_grid_adaboost}\n",
    "\n",
    "#grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "#grid.fit(X_test, y_test)\n",
    "\n",
    "#print(\"Best parameters: \", grid.best_params_)\n",
    "#print(\"Best score: \", grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combination of KNN with stacking ensemble method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'final_estimator__C': 0.1, 'knn__kneighborsclassifier__n_neighbors': 7, 'rf__max_depth': 3, 'rf__n_estimators': 50}\n",
      "Best score:  0.9636363636363636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('kneighborsclassifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "estimators = [('knn', knn), ('rf', rf)]\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "param_grid_knn = {'knn__kneighborsclassifier__n_neighbors': [3, 5, 7]}\n",
    "param_grid_rf = {'rf__n_estimators': [50, 100, 150], 'rf__max_depth': [3, 5, 7]}\n",
    "param_grid_stacking = {'final_estimator__C': [0.1, 1, 10]}\n",
    "\n",
    "param_grid = {**param_grid_knn, **param_grid_rf, **param_grid_stacking}\n",
    "\n",
    "grid = GridSearchCV(stacking, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logist_out2 = pd.DataFrame({'PassengerId':df_test.PassengerId, 'Transported': y_pred_log2})\n",
    "# Logist_out2.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression competition Score = **0.79448**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_out = pd.DataFrame({'PassengerId':df_test.PassengerId, 'Transported': y_pred_knn})\n",
    "# knn_out.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN competition score = **0.79261**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbr_out = pd.DataFrame({'PassengerId':df_test.PassengerId, 'Transported': pred_y_gbr})\n",
    "# gbr_out.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boost competition score = **0.80056**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_out = pd.DataFrame({'PassengerId':df_test.PassengerId, 'Transported':pred_y_gbr2})\n",
    "clf_out.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuned Gradient Boost competition score = **0.80476**\n",
    "\n",
    "And so, we have a winner.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
